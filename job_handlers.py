"""
ä»»åŠ¡å¤„ç†æ¨¡å—
å¤„ç†æ‰¹é‡æ¨ç†ä»»åŠ¡çš„å¯åŠ¨ã€çŠ¶æ€æŸ¥è¯¢ã€ç»“æœè·å–ç­‰
"""
import gradio as gr
import pandas as pd
from datetime import datetime
from config import TEXT_MODELS, IMAGE_MODELS, VIDEO_MODELS, current_job_info
from state_manager import save_job_state, load_job_state, create_batch_manager


def preview_files(input_bucket: str, input_prefix: str, aws_region: str) -> tuple:
    """é¢„è§ˆS3è¾“å…¥æ–‡ä»¶"""
    try:
        if not input_bucket:
            return None, "âŒ è¯·è¾“å…¥Bucketåç§°"
        
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        files = manager.list_input_files(input_bucket, input_prefix)
        
        if not files:
            return None, f"âš ï¸ åœ¨ {input_bucket}/{input_prefix} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶"
        
        # è½¬æ¢ä¸ºDataFrameç”¨äºæ˜¾ç¤º
        df = pd.DataFrame(files)
        message = f"âœ… æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶"
        
        return df, message
        
    except Exception as e:
        return None, f"âŒ é¢„è§ˆæ–‡ä»¶å¤±è´¥: {str(e)}"


def validate_configuration(
    input_bucket: str,
    output_bucket: str,
    role_arn: str,
    aws_region: str,
    model_name: str = None
) -> str:
    """éªŒè¯é…ç½®"""
    try:
        if not all([input_bucket, output_bucket, role_arn]):
            return "âŒ è¯·å¡«å†™æ‰€æœ‰å¿…å¡«é…ç½®é¡¹"
        
        # è·å–model_idï¼ˆå¦‚æœæä¾›äº†model_nameï¼‰
        model_id = None
        if model_name:
            # å°è¯•ä»ä¸åŒçš„æ¨¡å‹å­—å…¸ä¸­è·å–model_id
            model_id = (TEXT_MODELS.get(model_name) or 
                       IMAGE_MODELS.get(model_name) or 
                       VIDEO_MODELS.get(model_name))
        
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        result = manager.validate_permissions(role_arn, input_bucket, output_bucket, model_id)
        
        # æ„å»ºéªŒè¯ç»“æœæ¶ˆæ¯
        message_parts = ["### æƒé™éªŒè¯ç»“æœ\n"]
        message_parts.append(f"**AWS Region:** {aws_region}\n")
        if model_id:
            message_parts.append(f"**æ¨¡å‹ID:** {model_id}\n")
        
        # æ˜¾ç¤ºæ£€æŸ¥é€šè¿‡çš„é¡¹
        if result['checks']:
            message_parts.append("#### âœ… æ£€æŸ¥é€šè¿‡ï¼š")
            for check in result['checks']:
                message_parts.append(f"- {check}")
        
        # æ˜¾ç¤ºè­¦å‘Š
        if result.get('warnings'):
            message_parts.append("\n#### âš ï¸ è­¦å‘Šï¼š")
            for warning in result['warnings']:
                message_parts.append(f"- {warning}")
        
        # æ˜¾ç¤ºé”™è¯¯
        if result['errors']:
            message_parts.append("\n#### âŒ å‘ç°é—®é¢˜ï¼š")
            for error in result['errors']:
                message_parts.append(f"- {error}")
        
        if result['valid']:
            message_parts.append("\n### ğŸ‰ é…ç½®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹æ‰¹å¤„ç†ï¼")
        else:
            message_parts.append("\n### âš ï¸ è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åå†æäº¤ä»»åŠ¡")
        
        return "\n".join(message_parts)
        
    except Exception as e:
        return f"âŒ éªŒè¯å¤±è´¥: {str(e)}"


def start_batch_job(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    output_bucket: str = "",
    output_prefix: str = "",
    prompt: str = "",
    model_name: str = "",
    role_arn: str = "",
    aws_region: str = "us-east-1",
    progress=gr.Progress()
) -> tuple:
    """å¯åŠ¨æ–‡æœ¬æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼‰"""
    # åˆå§‹åŒ–å¤„ç†æ—¥å¿—
    processing_log = []
    
    def log_callback(step: str, current: int, total: int, details: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        
        if step == 'scan':
            emoji = 'ğŸ”'
        elif step == 'process':
            emoji = 'ğŸ“„'
            if total > 0:
                progress_pct = (current / total * 0.6) + 0.3
                progress(progress_pct, desc=f"å¤„ç†æ–‡ä»¶ {current}/{total}")
        elif step == 'generate':
            emoji = 'ğŸ“'
            progress(0.9, desc="ç”ŸæˆJSONLæ–‡ä»¶...")
        elif step == 'error':
            emoji = 'âŒ'
        else:
            emoji = 'â³'
        
        log_entry = f"{emoji} [{timestamp}] {details}"
        processing_log.append(log_entry)
    
    try:
        # åŸºç¡€éªŒè¯
        if not all([output_bucket, model_name, role_arn]):
            return (
                "âŒ è¯·å¡«å†™æ‰€æœ‰å¿…å¡«å­—æ®µ",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        model_id = TEXT_MODELS.get(model_name)
        if not model_id:
            return (
                "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        progress(0, desc="æ­£åœ¨åˆå§‹åŒ–...")
        log_callback('init', 0, 0, 'æ­£åœ¨åˆå§‹åŒ–æ‰¹å¤„ç†ç®¡ç†å™¨...')
        
        # åˆ›å»ºç®¡ç†å™¨
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†é€»è¾‘
        if use_jsonl:
            # JSONLæ–‡ä»¶æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å·²æœ‰çš„JSONLæ–‡ä»¶
            if not jsonl_s3_uri:
                return (
                    "âŒ è¯·è¾“å…¥JSONLæ–‡ä»¶çš„S3 URI",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
            
            log_callback('jsonl', 0, 1, f'ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶: {jsonl_s3_uri}')
            progress(0.5, desc="æ­£åœ¨æäº¤æ‰¹å¤„ç†ä»»åŠ¡...")
            
            # ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶åˆ›å»ºä»»åŠ¡
            result = manager.create_batch_job_from_jsonl(
                jsonl_s3_uri=jsonl_s3_uri,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn
            )
            
            log_callback('jsonl', 1, 1, 'âœ… ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶ï¼Œè·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤')
        else:
            # åŸå§‹æ–‡ä»¶æ¨¡å¼ï¼šè¯»å–æ–‡ä»¶å¹¶ç”ŸæˆJSONL
            if not all([input_bucket, prompt]):
                return (
                    "âŒ åŸå§‹æ–‡ä»¶æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒPrompt",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
            
            # åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
            result = manager.create_batch_job(
                input_bucket=input_bucket,
                input_prefix=input_prefix,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn,
                prompt=prompt,
                progress_callback=log_callback
            )
        
        if not result['success']:
            return (
                f"âŒ {result['message']}",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                "\n".join(processing_log)
            )
        
        # ä¿å­˜ä»»åŠ¡ä¿¡æ¯åˆ°å†…å­˜
        current_job_info['job_arn'] = result['job_arn']
        current_job_info['manager'] = manager
        current_job_info['output_bucket'] = output_bucket
        current_job_info['output_prefix'] = output_prefix
        current_job_info['aws_region'] = aws_region
        current_job_info['input_bucket'] = input_bucket
        current_job_info['input_prefix'] = input_prefix
        current_job_info['job_type'] = 'text'  # æ ‡è®°ä»»åŠ¡ç±»å‹
        
        # æŒä¹…åŒ–ä¿å­˜ä»»åŠ¡çŠ¶æ€åˆ°æ–‡ä»¶
        save_job_state(result['job_arn'], {
            'output_bucket': output_bucket,
            'output_prefix': output_prefix,
            'aws_region': aws_region,
            'input_bucket': input_bucket,
            'input_prefix': input_prefix,
            'job_type': 'text'
        })
        
        progress(1.0, desc="ä»»åŠ¡å·²æäº¤...")
        log_callback('submit', 1, 1, f'âœ… æ‰¹å¤„ç†ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ°Bedrock')
        
        # æ„å»ºçŠ¶æ€æ¶ˆæ¯
        status_msg = f"""
### âœ… æ‰¹å¤„ç†ä»»åŠ¡å·²æäº¤

**ä»»åŠ¡ä¿¡æ¯ï¼š**
- ä»»åŠ¡åç§°: {result['job_name']}
- ä»»åŠ¡ARN: {result['job_arn']}
- æ¨¡å‹: {model_name}
- AWS Region: {aws_region}
- çŠ¶æ€: å·²æäº¤

{result['message']}

*ä»»åŠ¡æ­£åœ¨åå°æ‰§è¡Œï¼Œè¯·ç‚¹å‡»"åˆ·æ–°çŠ¶æ€"æŒ‰é’®æŸ¥çœ‹æœ€æ–°è¿›åº¦*
"""
        
        return (
            status_msg,
            result['job_arn'],
            gr.update(visible=True),
            gr.update(visible=True),
            "\n".join(processing_log)
        )
        
    except Exception as e:
        log_callback('error', 0, 0, f'å‘ç”Ÿé”™è¯¯: {str(e)}')
        return (
            f"âŒ å¯åŠ¨ä»»åŠ¡å¤±è´¥: {str(e)}",
            None,
            gr.update(visible=False),
            gr.update(visible=False),
            "\n".join(processing_log)
        )


def start_image_batch_job(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    output_bucket: str,
    output_prefix: str,
    model_name: str,
    role_arn: str,
    system_prompt: str,
    user_prompt: str,
    aws_region: str = "us-east-1",
    progress=gr.Progress()
) -> tuple:
    """å¯åŠ¨å›¾ç‰‡æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼‰"""
    # åˆå§‹åŒ–å¤„ç†æ—¥å¿—
    processing_log = []
    
    def log_callback(step: str, current: int, total: int, details: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        
        if step == 'scan':
            emoji = 'ğŸ”'
        elif step == 'process':
            emoji = 'ğŸ–¼ï¸'
            if total > 0:
                progress_pct = (current / total * 0.6) + 0.3
                progress(progress_pct, desc=f"å¤„ç†å›¾ç‰‡ {current}/{total}")
        elif step == 'generate':
            emoji = 'ğŸ“'
            progress(0.9, desc="ç”ŸæˆJSONLæ–‡ä»¶...")
        elif step == 'error':
            emoji = 'âŒ'
        else:
            emoji = 'â³'
        
        log_entry = f"{emoji} [{timestamp}] {details}"
        processing_log.append(log_entry)
    
    try:
        # åŸºç¡€éªŒè¯
        if not all([output_bucket, model_name, role_arn]):
            return (
                "âŒ è¯·å¡«å†™æ‰€æœ‰å¿…å¡«å­—æ®µ",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        # æ¨¡å¼ç‰¹å®šéªŒè¯
        if use_jsonl:
            if not jsonl_s3_uri:
                return (
                    "âŒ JSONLæ¨¡å¼éœ€è¦å¡«å†™JSONLæ–‡ä»¶S3 URI",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
        else:
            if not all([input_bucket, user_prompt]):
                return (
                    "âŒ åŸå§‹å›¾ç‰‡æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒUser Prompt",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
        
        model_id = IMAGE_MODELS.get(model_name)
        if not model_id:
            return (
                "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        progress(0, desc="æ­£åœ¨åˆå§‹åŒ–...")
        log_callback('init', 0, 0, 'æ­£åœ¨åˆå§‹åŒ–å›¾ç‰‡æ‰¹å¤„ç†ç®¡ç†å™¨...')
        
        # åˆ›å»ºç®¡ç†å™¨
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†é€»è¾‘
        if use_jsonl:
            # JSONLæ–‡ä»¶æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å·²æœ‰çš„JSONLæ–‡ä»¶
            if not jsonl_s3_uri:
                return (
                    "âŒ è¯·è¾“å…¥JSONLæ–‡ä»¶çš„S3 URI",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
            
            log_callback('jsonl', 0, 1, f'ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶: {jsonl_s3_uri}')
            progress(0.5, desc="æ­£åœ¨æäº¤æ‰¹å¤„ç†ä»»åŠ¡...")
            
            # ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶åˆ›å»ºä»»åŠ¡
            result = manager.create_batch_job_from_jsonl(
                jsonl_s3_uri=jsonl_s3_uri,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn
            )
            
            log_callback('jsonl', 1, 1, 'âœ… ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶ï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†æ­¥éª¤')
        else:
            # åŸå§‹å›¾ç‰‡æ¨¡å¼ï¼šè¯»å–å›¾ç‰‡å¹¶ç”ŸæˆJSONL
            if not user_prompt:
                return (
                    "âŒ åŸå§‹å›¾ç‰‡æ¨¡å¼éœ€è¦å¡«å†™User Prompt",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
            
            # åˆ›å»ºå›¾ç‰‡æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
            result = manager.create_image_batch_job(
                input_bucket=input_bucket,
                input_prefix=input_prefix,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                progress_callback=log_callback
            )
        
        if not result['success']:
            return (
                f"âŒ {result['message']}",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                "\n".join(processing_log)
            )
        
        # ä¿å­˜ä»»åŠ¡ä¿¡æ¯åˆ°å†…å­˜
        current_job_info['job_arn'] = result['job_arn']
        current_job_info['manager'] = manager
        current_job_info['output_bucket'] = output_bucket
        current_job_info['output_prefix'] = output_prefix
        current_job_info['aws_region'] = aws_region
        current_job_info['input_bucket'] = input_bucket
        current_job_info['input_prefix'] = input_prefix
        current_job_info['job_type'] = 'image'  # æ ‡è®°ä»»åŠ¡ç±»å‹
        
        # æŒä¹…åŒ–ä¿å­˜ä»»åŠ¡çŠ¶æ€åˆ°æ–‡ä»¶
        save_job_state(result['job_arn'], {
            'output_bucket': output_bucket,
            'output_prefix': output_prefix,
            'aws_region': aws_region,
            'input_bucket': input_bucket,
            'input_prefix': input_prefix,
            'job_type': 'image'
        })
        
        progress(1.0, desc="ä»»åŠ¡å·²æäº¤...")
        log_callback('submit', 1, 1, f'âœ… å›¾ç‰‡æ‰¹å¤„ç†ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ°Bedrock')
        
        # æ„å»ºçŠ¶æ€æ¶ˆæ¯
        status_msg = f"""
### âœ… å›¾ç‰‡æ‰¹å¤„ç†ä»»åŠ¡å·²æäº¤

**ä»»åŠ¡ä¿¡æ¯ï¼š**
- ä»»åŠ¡åç§°: {result['job_name']}
- ä»»åŠ¡ARN: {result['job_arn']}
- æ¨¡å‹: {model_name}
- AWS Region: {aws_region}
- çŠ¶æ€: å·²æäº¤

{result['message']}

*ä»»åŠ¡æ­£åœ¨åå°æ‰§è¡Œï¼Œè¯·ç‚¹å‡»"åˆ·æ–°çŠ¶æ€"æŒ‰é’®æŸ¥çœ‹æœ€æ–°è¿›åº¦*
"""
        
        return (
            status_msg,
            result['job_arn'],
            gr.update(visible=True),
            gr.update(visible=True),
            "\n".join(processing_log)
        )
        
    except Exception as e:
        log_callback('error', 0, 0, f'å‘ç”Ÿé”™è¯¯: {str(e)}')
        return (
            f"âŒ å¯åŠ¨å›¾ç‰‡æ‰¹å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}",
            None,
            gr.update(visible=False),
            gr.update(visible=False),
            "\n".join(processing_log)
        )


def refresh_job_status(job_arn: str) -> tuple:
    """åˆ·æ–°ä»»åŠ¡çŠ¶æ€"""
    try:
        if not job_arn or not current_job_info['manager']:
            return "âš ï¸ æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡", None, gr.update(visible=False, interactive=False)
        
        manager = current_job_info['manager']
        status_info = manager.get_job_status(job_arn)
        
        status = status_info.get('status', 'Unknown')
        
        # çŠ¶æ€æ˜ å°„
        status_emoji = {
            'Submitted': 'ğŸ“',
            'InProgress': 'â³',
            'Completed': 'âœ…',
            'Failed': 'âŒ',
            'Stopped': 'ğŸ›‘',
            'Error': 'âŒ'
        }
        
        emoji = status_emoji.get(status, 'â“')
        
        # æ„å»ºçŠ¶æ€æ¶ˆæ¯
        status_msg = f"""
### {emoji} ä»»åŠ¡çŠ¶æ€: {status}

**ä»»åŠ¡è¯¦æƒ…ï¼š**
- ä»»åŠ¡ARN: {job_arn}
- æäº¤æ—¶é—´: {status_info.get('submit_time', 'N/A')}
- æœ€åæ›´æ–°: {status_info.get('last_modified', 'N/A')}
- å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        if status_info.get('message'):
            status_msg += f"\n**æ¶ˆæ¯:** {status_info['message']}"
        
        # æŒ‰é’®çŠ¶æ€æ§åˆ¶ï¼šä»»åŠ¡å®Œæˆæ—¶æ‰å¯ç‚¹å‡»
        button_interactive = status == 'Completed'
        
        if status == 'Completed':
            status_msg += "\n\n### ğŸ‰ ä»»åŠ¡å·²å®Œæˆï¼\nè¯·ç‚¹å‡»ä¸‹æ–¹'è·å–ç»“æœ'æŒ‰é’®æŸ¥çœ‹å¤„ç†ç»“æœã€‚"
        elif status == 'Failed':
            status_msg += "\n\n### âŒ ä»»åŠ¡å¤±è´¥\nè¯·æ£€æŸ¥é…ç½®å’Œæƒé™è®¾ç½®ã€‚"
        elif status in ['Submitted', 'InProgress']:
            status_msg += "\n\n*ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åå†æ¬¡åˆ·æ–°...*"
        
        return (
            status_msg,
            None if not button_interactive else "ready",
            gr.update(visible=True, interactive=button_interactive)
        )
        
    except Exception as e:
        return f"âŒ è·å–çŠ¶æ€å¤±è´¥: {str(e)}", None, gr.update(visible=False, interactive=False)


def get_results(job_arn: str) -> tuple:
    """è·å–ä»»åŠ¡ç»“æœï¼ˆé¢„è§ˆ+æ–‡ä»¶ä½ç½®ï¼‰"""
    try:
        if not job_arn or not current_job_info['manager']:
            return "âš ï¸ æ²¡æœ‰å¯ç”¨çš„ä»»åŠ¡ç»“æœ", "", None
        
        manager = current_job_info['manager']
        output_bucket = current_job_info['output_bucket']
        output_prefix = current_job_info['output_prefix']
        job_type = current_job_info.get('job_type', 'text')  # é»˜è®¤ä¸ºæ–‡æœ¬ç±»å‹
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®é¢„è§ˆè¡Œæ•°ï¼šè§†é¢‘1è¡Œï¼Œæ–‡æœ¬/å›¾ç‰‡3è¡Œ
        max_preview_lines = 1 if job_type == 'video' else 3
        
        # è·å–ç»“æœé¢„è§ˆå’Œæ–‡ä»¶ä½ç½®ï¼ˆä¸ç”Ÿæˆä¸‹è½½é“¾æ¥ï¼‰
        result_data = manager.get_results_preview_only(job_arn, output_bucket, output_prefix, max_preview_lines)
        
        preview = result_data['preview']
        s3_uri = result_data['s3_uri']
        file_name = result_data['file_name']
        bucket = result_data['bucket']
        key = result_data['key']
        parse_warning = result_data.get('parse_warning', '')
        manifest = result_data.get('manifest')
        manifest_s3_uri = result_data.get('manifest_s3_uri')
        
        # è½¬æ¢é¢„è§ˆæ•°æ®ä¸ºDataFrameï¼ˆæˆªå–output_textå‰200å­—ç¬¦ï¼‰
        preview_data = []
        for item in preview:
            preview_data.append({
                'record_id': item['record_id'],
                'output_text': item['output_text'][:200] + '...' if len(item['output_text']) > 200 else item['output_text'],
                'stop_reason': item['stop_reason']
            })
        
        df = pd.DataFrame(preview_data) if preview_data else None
        
        # æ„å»ºç»“æœæ¶ˆæ¯
        if parse_warning:
            message = f"""
### âš ï¸ ç»“æœæ–‡ä»¶å·²æ‰¾åˆ°ï¼Œä½†é¢„è§ˆæ•°æ®è§£æå¤±è´¥

#### ğŸ“‚ ç»“æœæ–‡ä»¶ä½ç½®
- **S3 URI**: `{s3_uri}`
- **Bucket**: {bucket}
- **Key**: {key}
- **æ–‡ä»¶å**: {file_name}

#### âš ï¸ è§£æè­¦å‘Š
{parse_warning}

---
ğŸ’¡ **æç¤º**: è¯·ç›´æ¥ä½¿ç”¨AWS CLIæˆ–AWS Consoleè®¿é—®å®Œæ•´çš„JSONLæ–‡ä»¶æŸ¥çœ‹ç»“æœå†…å®¹ã€‚
"""
        else:
            message = f"""
### âœ… ç»“æœè·å–æˆåŠŸ

#### ğŸ“‚ ç»“æœæ–‡ä»¶ä½ç½®
- **S3 URI**: `{s3_uri}`
- **Bucket**: {bucket}
- **Key**: {key}
- **æ–‡ä»¶å**: {file_name}
"""
            
            # æ·»åŠ manifestä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if manifest:
                message += f"""
#### ğŸ“Š ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯ (Manifest)
- **æ€»è®°å½•æ•°**: {manifest.get('totalRecordCount', 'N/A')}
- **å·²å¤„ç†è®°å½•æ•°**: {manifest.get('processedRecordCount', 'N/A')}
- **æˆåŠŸè®°å½•æ•°**: {manifest.get('successRecordCount', 'N/A')}
- **å¤±è´¥è®°å½•æ•°**: {manifest.get('errorRecordCount', 'N/A')}
- **è¾“å…¥Tokenæ•°**: {manifest.get('inputTokenCount', 'N/A')}
- **è¾“å‡ºTokenæ•°**: {manifest.get('outputTokenCount', 'N/A')}
- **Manifestæ–‡ä»¶**: `{manifest_s3_uri}`
"""
            
            message += """
#### ğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰å‡ è¡Œï¼‰
*ä¸‹æ–¹è¡¨æ ¼æ˜¾ç¤ºéƒ¨åˆ†è®°å½•çš„é¢„è§ˆ*

---
ğŸ’¡ **æç¤º**: å®Œæ•´ç»“æœä¿å­˜åœ¨ä¸Šè¿°S3ä½ç½®ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨AWS CLIæˆ–AWS Consoleè®¿é—®å®Œæ•´çš„JSONLæ–‡ä»¶ã€‚
"""
        
        # æ„å»ºæ–‡ä»¶ä½ç½®ä¿¡æ¯HTMLï¼ˆæ›¿ä»£ä¸‹è½½é“¾æ¥ï¼‰
        location_html = f"""
        <div style="padding: 20px; background-color: #f0f8ff; border-radius: 10px; border: 2px solid #4CAF50;">
            <h3 style="margin-top: 0; color: #2c3e50;">ğŸ“‚ ç»“æœæ–‡ä»¶ä½ç½®</h3>
            <div style="background-color: #ffffff; padding: 15px; border-radius: 5px; margin: 10px 0; font-family: monospace;">
                <p style="margin: 5px 0;"><strong>S3 URI:</strong></p>
                <p style="margin: 5px 0; color: #0066cc; word-break: break-all;">{s3_uri}</p>
            </div>
            <div style="margin-top: 15px;">
                <p style="margin: 5px 0; font-size: 0.9em;"><strong>è®¿é—®æ–¹å¼:</strong></p>
                <ul style="margin: 5px 0; padding-left: 20px; font-size: 0.9em;">
                    <li>ä½¿ç”¨AWS CLI: <code style="background-color: #f5f5f5; padding: 2px 5px; border-radius: 3px;">aws s3 cp {s3_uri} .</code></li>
                    <li>åœ¨AWS Consoleçš„S3æœåŠ¡ä¸­æœç´¢: <strong>{bucket}</strong></li>
                </ul>
            </div>
        </div>
        """
        
        return message, location_html, df
        
    except Exception as e:
        return f"âŒ è·å–ç»“æœå¤±è´¥: {str(e)}", "", None


def start_video_batch_job(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    output_bucket: str,
    output_prefix: str,
    model_name: str,
    role_arn: str,
    system_prompt: str,
    user_prompt: str,
    aws_region: str = "us-west-2",
    progress=gr.Progress()
) -> tuple:
    """å¯åŠ¨è§†é¢‘æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼‰"""
    # åˆå§‹åŒ–å¤„ç†æ—¥å¿—
    processing_log = []
    
    def log_callback(step: str, current: int, total: int, details: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        
        if step == 'scan':
            emoji = 'ğŸ”'
        elif step == 'process':
            emoji = 'ğŸ¬'
            if total > 0:
                progress_pct = (current / total * 0.6) + 0.3
                progress(progress_pct, desc=f"å¤„ç†è§†é¢‘ {current}/{total}")
        elif step == 'generate':
            emoji = 'ğŸ“'
            progress(0.9, desc="ç”ŸæˆJSONLæ–‡ä»¶...")
        elif step == 'error':
            emoji = 'âŒ'
        else:
            emoji = 'â³'
        
        log_entry = f"{emoji} [{timestamp}] {details}"
        processing_log.append(log_entry)
    
    try:
        # åŸºç¡€éªŒè¯
        if not all([output_bucket, model_name, role_arn]):
            return (
                "âŒ è¯·å¡«å†™æ‰€æœ‰å¿…å¡«å­—æ®µ",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        # æ¨¡å¼ç‰¹å®šéªŒè¯
        if use_jsonl:
            if not jsonl_s3_uri:
                return (
                    "âŒ JSONLæ¨¡å¼éœ€è¦å¡«å†™JSONLæ–‡ä»¶S3 URI",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
        else:
            if not all([input_bucket, user_prompt]):
                return (
                    "âŒ åŸå§‹è§†é¢‘æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒUser Prompt",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
        
        model_id = VIDEO_MODELS.get(model_name)
        if not model_id:
            return (
                "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                ""
            )
        
        progress(0, desc="æ­£åœ¨åˆå§‹åŒ–...")
        log_callback('init', 0, 0, 'æ­£åœ¨åˆå§‹åŒ–è§†é¢‘æ‰¹å¤„ç†ç®¡ç†å™¨...')
        
        # åˆ›å»ºç®¡ç†å™¨
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†é€»è¾‘
        if use_jsonl:
            # JSONLæ–‡ä»¶æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å·²æœ‰çš„JSONLæ–‡ä»¶
            log_callback('jsonl', 0, 1, f'ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶: {jsonl_s3_uri}')
            progress(0.5, desc="æ­£åœ¨æäº¤æ‰¹å¤„ç†ä»»åŠ¡...")
            
            # ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶åˆ›å»ºä»»åŠ¡
            result = manager.create_batch_job_from_jsonl(
                jsonl_s3_uri=jsonl_s3_uri,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn
            )
            
            log_callback('jsonl', 1, 1, 'âœ… ä½¿ç”¨å·²æœ‰JSONLæ–‡ä»¶ï¼Œè·³è¿‡è§†é¢‘å¤„ç†æ­¥éª¤')
        else:
            # åŸå§‹è§†é¢‘æ¨¡å¼ï¼šè¯»å–è§†é¢‘å¹¶ç”ŸæˆJSONL
            if not user_prompt:
                return (
                    "âŒ åŸå§‹è§†é¢‘æ¨¡å¼éœ€è¦å¡«å†™User Prompt",
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    ""
                )
            
            # åˆ›å»ºè§†é¢‘æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
            result = manager.create_video_batch_job(
                input_bucket=input_bucket,
                input_prefix=input_prefix,
                output_bucket=output_bucket,
                output_prefix=output_prefix,
                model_id=model_id,
                role_arn=role_arn,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                progress_callback=log_callback
            )
        
        if not result['success']:
            return (
                f"âŒ {result['message']}",
                None,
                gr.update(visible=False),
                gr.update(visible=False),
                "\n".join(processing_log)
            )
        
        # ä¿å­˜ä»»åŠ¡ä¿¡æ¯åˆ°å†…å­˜
        current_job_info['job_arn'] = result['job_arn']
        current_job_info['manager'] = manager
        current_job_info['output_bucket'] = output_bucket
        current_job_info['output_prefix'] = output_prefix
        current_job_info['aws_region'] = aws_region
        current_job_info['input_bucket'] = input_bucket
        current_job_info['input_prefix'] = input_prefix
        current_job_info['job_type'] = 'video'  # æ ‡è®°ä»»åŠ¡ç±»å‹
        
        # æŒä¹…åŒ–ä¿å­˜ä»»åŠ¡çŠ¶æ€åˆ°æ–‡ä»¶
        save_job_state(result['job_arn'], {
            'output_bucket': output_bucket,
            'output_prefix': output_prefix,
            'aws_region': aws_region,
            'input_bucket': input_bucket,
            'input_prefix': input_prefix,
            'job_type': 'video'
        })
        
        progress(1.0, desc="ä»»åŠ¡å·²æäº¤...")
        log_callback('submit', 1, 1, f'âœ… è§†é¢‘æ‰¹å¤„ç†ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ°Bedrock')
        
        # æ„å»ºçŠ¶æ€æ¶ˆæ¯
        status_msg = f"""
### âœ… è§†é¢‘æ‰¹å¤„ç†ä»»åŠ¡å·²æäº¤

**ä»»åŠ¡ä¿¡æ¯ï¼š**
- ä»»åŠ¡åç§°: {result['job_name']}
- ä»»åŠ¡ARN: {result['job_arn']}
- æ¨¡å‹: {model_name}
- AWS Region: {aws_region}
- çŠ¶æ€: å·²æäº¤

{result['message']}

*ä»»åŠ¡æ­£åœ¨åå°æ‰§è¡Œï¼Œè¯·ç‚¹å‡»"åˆ·æ–°çŠ¶æ€"æŒ‰é’®æŸ¥çœ‹æœ€æ–°è¿›åº¦*
"""
        
        return (
            status_msg,
            result['job_arn'],
            gr.update(visible=True),
            gr.update(visible=True),
            "\n".join(processing_log)
        )
        
    except Exception as e:
        log_callback('error', 0, 0, f'å‘ç”Ÿé”™è¯¯: {str(e)}')
        return (
            f"âŒ å¯åŠ¨è§†é¢‘æ‰¹å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}",
            None,
            gr.update(visible=False),
            gr.update(visible=False),
            "\n".join(processing_log)
        )


def validate_text_single_inference(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    prompt: str,
    model_name: str,
    aws_region: str
) -> str:
    """éªŒè¯æ–‡æœ¬æ‰¹å¤„ç†çš„å•æ¬¡æ¨ç†"""
    try:
        if not model_name:
            return "âŒ è¯·é€‰æ‹©æ¨¡å‹"
        
        model_id = TEXT_MODELS.get(model_name)
        if not model_id:
            return "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©"
        
        # æ¨¡å¼éªŒè¯
        if use_jsonl:
            if not jsonl_s3_uri:
                return "âŒ JSONLæ¨¡å¼éœ€è¦å¡«å†™JSONLæ–‡ä»¶S3 URI"
        else:
            if not all([input_bucket, prompt]):
                return "âŒ åŸå§‹æ–‡ä»¶æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒPrompt"
        
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        result = manager.validate_single_text_inference(
            use_jsonl=use_jsonl,
            input_bucket=input_bucket,
            input_prefix=input_prefix,
            jsonl_s3_uri=jsonl_s3_uri,
            prompt=prompt,
            model_id=model_id
        )
        
        if result['success']:
            return f"""
### âœ… å•æ¬¡æ¨ç†éªŒè¯æˆåŠŸï¼

#### ğŸ“ éªŒè¯ä¿¡æ¯
- **éªŒè¯æ–‡ä»¶**: {result['file_info']}
- **ä½¿ç”¨æ¨¡å‹**: {model_name}
- **æ¨ç†è€—æ—¶**: {result['duration']:.2f}ç§’

#### ğŸ“Š Tokenç»Ÿè®¡
- **è¾“å…¥Tokens**: {result['input_tokens']}
- **è¾“å‡ºTokens**: {result['output_tokens']}
- **åœæ­¢åŸå› **: {result['stop_reason']}

#### ğŸ’¬ æ¨¡å‹è¾“å‡º
{result['output_text']}

---
ğŸ’¡ **æç¤º**: éªŒè¯æˆåŠŸï¼Promptç»„è£…å’Œæ¨¡å‹è°ƒç”¨å‡æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æ‰¹å¤„ç†ä»»åŠ¡ã€‚
"""
        else:
            return f"""
### âŒ å•æ¬¡æ¨ç†éªŒè¯å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: {result['error']}

---
ğŸ’¡ **æç¤º**: è¯·æ£€æŸ¥é…ç½®å‚æ•°å’Œæƒé™è®¾ç½®ï¼Œä¿®å¤é—®é¢˜åé‡æ–°éªŒè¯ã€‚
"""
    
    except Exception as e:
        return f"âŒ éªŒè¯å¤±è´¥: {str(e)}"


def validate_image_single_inference(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    system_prompt: str,
    user_prompt: str,
    model_name: str,
    aws_region: str
) -> str:
    """éªŒè¯å›¾ç‰‡æ‰¹å¤„ç†çš„å•æ¬¡æ¨ç†"""
    try:
        if not model_name:
            return "âŒ è¯·é€‰æ‹©æ¨¡å‹"
        
        model_id = IMAGE_MODELS.get(model_name)
        if not model_id:
            return "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©"
        
        # æ¨¡å¼éªŒè¯
        if use_jsonl:
            if not jsonl_s3_uri:
                return "âŒ JSONLæ¨¡å¼éœ€è¦å¡«å†™JSONLæ–‡ä»¶S3 URI"
        else:
            if not all([input_bucket, user_prompt]):
                return "âŒ åŸå§‹å›¾ç‰‡æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒUser Prompt"
        
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        result = manager.validate_single_image_inference(
            use_jsonl=use_jsonl,
            input_bucket=input_bucket,
            input_prefix=input_prefix,
            jsonl_s3_uri=jsonl_s3_uri,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model_id=model_id
        )
        
        if result['success']:
            return f"""
### âœ… å•æ¬¡æ¨ç†éªŒè¯æˆåŠŸï¼

#### ğŸ–¼ï¸ éªŒè¯ä¿¡æ¯
- **éªŒè¯æ–‡ä»¶**: {result['file_info']}
- **ä½¿ç”¨æ¨¡å‹**: {model_name}
- **æ¨ç†è€—æ—¶**: {result['duration']:.2f}ç§’

#### ğŸ“Š Tokenç»Ÿè®¡
- **è¾“å…¥Tokens**: {result['input_tokens']}
- **è¾“å‡ºTokens**: {result['output_tokens']}
- **åœæ­¢åŸå› **: {result['stop_reason']}

#### ğŸ’¬ æ¨¡å‹è¾“å‡º
{result['output_text']}

---
ğŸ’¡ **æç¤º**: éªŒè¯æˆåŠŸï¼å›¾ç‰‡å¤„ç†å’Œæ¨¡å‹è°ƒç”¨å‡æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æ‰¹å¤„ç†ä»»åŠ¡ã€‚
"""
        else:
            return f"""
### âŒ å•æ¬¡æ¨ç†éªŒè¯å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: {result['error']}

---
ğŸ’¡ **æç¤º**: è¯·æ£€æŸ¥é…ç½®å‚æ•°ã€å›¾ç‰‡æ ¼å¼å’Œæƒé™è®¾ç½®ï¼Œä¿®å¤é—®é¢˜åé‡æ–°éªŒè¯ã€‚
"""
    
    except Exception as e:
        return f"âŒ éªŒè¯å¤±è´¥: {str(e)}"


def validate_video_single_inference(
    use_jsonl: bool,
    input_bucket: str,
    input_prefix: str,
    jsonl_s3_uri: str,
    system_prompt: str,
    user_prompt: str,
    model_name: str,
    aws_region: str
) -> str:
    """éªŒè¯è§†é¢‘æ‰¹å¤„ç†çš„å•æ¬¡æ¨ç†"""
    try:
        if not model_name:
            return "âŒ è¯·é€‰æ‹©æ¨¡å‹"
        
        model_id = VIDEO_MODELS.get(model_name)
        if not model_id:
            return "âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©"
        
        # æ¨¡å¼éªŒè¯
        if use_jsonl:
            if not jsonl_s3_uri:
                return "âŒ JSONLæ¨¡å¼éœ€è¦å¡«å†™JSONLæ–‡ä»¶S3 URI"
        else:
            if not all([input_bucket, user_prompt]):
                return "âŒ åŸå§‹è§†é¢‘æ¨¡å¼éœ€è¦å¡«å†™è¾“å…¥Bucketå’ŒUser Prompt"
        
        manager = create_batch_manager(bedrock_region=aws_region, s3_region=aws_region)
        
        result = manager.validate_single_video_inference(
            use_jsonl=use_jsonl,
            input_bucket=input_bucket,
            input_prefix=input_prefix,
            jsonl_s3_uri=jsonl_s3_uri,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            model_id=model_id
        )
        
        if result['success']:
            return f"""
### âœ… å•æ¬¡æ¨ç†éªŒè¯æˆåŠŸï¼

#### ğŸ¬ éªŒè¯ä¿¡æ¯
- **éªŒè¯æ–‡ä»¶**: {result['file_info']}
- **ä½¿ç”¨æ¨¡å‹**: {model_name}
- **æ¨ç†è€—æ—¶**: {result['duration']:.2f}ç§’

#### ğŸ“Š Tokenç»Ÿè®¡
- **è¾“å…¥Tokens**: {result['input_tokens']}
- **è¾“å‡ºTokens**: {result['output_tokens']}
- **åœæ­¢åŸå› **: {result['stop_reason']}

#### ğŸ’¬ æ¨¡å‹è¾“å‡º
{result['output_text']}

---
ğŸ’¡ **æç¤º**: éªŒè¯æˆåŠŸï¼è§†é¢‘å¤„ç†å’Œæ¨¡å‹è°ƒç”¨å‡æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹æ‰¹å¤„ç†ä»»åŠ¡ã€‚
"""
        else:
            return f"""
### âŒ å•æ¬¡æ¨ç†éªŒè¯å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: {result['error']}

---
ğŸ’¡ **æç¤º**: è¯·æ£€æŸ¥é…ç½®å‚æ•°ã€è§†é¢‘æ ¼å¼å’Œæƒé™è®¾ç½®ï¼Œä¿®å¤é—®é¢˜åé‡æ–°éªŒè¯ã€‚
"""
    
    except Exception as e:
        return f"âŒ éªŒè¯å¤±è´¥: {str(e)}"
