"""
å•æ¬¡æŽ¨ç†éªŒè¯æ¨¡å—
ç”¨äºŽåœ¨æ‰¹å¤„ç†å‰éªŒè¯promptç»„è£…å’Œæ¨¡åž‹è°ƒç”¨çš„æ­£ç¡®æ€§
"""
import boto3
import json
import random
import base64
import logging
from typing import Dict, Optional, Tuple
from datetime import datetime
from .s3_manager import S3Manager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - [SingleInferenceValidator] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)


class SingleInferenceValidator:
    """å•æ¬¡æŽ¨ç†éªŒè¯å™¨"""
    
    def __init__(self, bedrock_region: str, s3_manager: S3Manager):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            bedrock_region: BedrockæœåŠ¡æ‰€åœ¨åŒºåŸŸ
            s3_manager: S3ç®¡ç†å™¨å®žä¾‹
        """
        self.bedrock_runtime = boto3.client('bedrock-runtime', region_name=bedrock_region)
        self.s3_manager = s3_manager
        self.bedrock_region = bedrock_region
    
    def validate_text_inference(
        self,
        use_jsonl: bool,
        input_bucket: str,
        input_prefix: str,
        jsonl_s3_uri: str,
        prompt: str,
        model_id: str
    ) -> Dict:
        """
        éªŒè¯æ–‡æœ¬æ‰¹å¤„ç†çš„å•æ¬¡æŽ¨ç†
        
        Args:
            use_jsonl: æ˜¯å¦ä½¿ç”¨JSONLæ–‡ä»¶æ¨¡å¼
            input_bucket: è¾“å…¥bucketï¼ˆåŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼‰
            input_prefix: è¾“å…¥è·¯å¾„å‰ç¼€ï¼ˆåŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼‰
            jsonl_s3_uri: JSONLæ–‡ä»¶URIï¼ˆJSONLæ¨¡å¼ï¼‰
            prompt: æç¤ºè¯
            model_id: æ¨¡åž‹ID
            
        Returns:
            éªŒè¯ç»“æžœå­—å…¸
        """
        logger.info("ðŸ§ª å¼€å§‹æ–‡æœ¬æŽ¨ç†éªŒè¯...")
        try:
            if use_jsonl:
                # JSONLæ¨¡å¼ï¼šè¯»å–ç¬¬ä¸€ä¸ªitem
                logger.debug("JSONLæ¨¡å¼ï¼šè¯»å–ç¬¬ä¸€ä¸ªitem")
                model_input, file_info = self._get_first_jsonl_item(jsonl_s3_uri)
                
                # æ£€æŸ¥JSONLæ ¼å¼æ˜¯å¦ä¸Žå½“å‰æ¨¡åž‹åŒ¹é…
                is_nova_model = 'nova' in model_id.lower()
                is_nova_format = 'schemaVersion' in model_input and 'inferenceConfig' in model_input
                is_claude_format = 'anthropic_version' in model_input and 'max_tokens' in model_input
                
                if is_nova_model and is_claude_format:
                    logger.warning("âš ï¸ JSONLæ–‡ä»¶ä¸ºClaudeæ ¼å¼ï¼Œä½†é€‰æ‹©äº†Novaæ¨¡åž‹")
                    return self._error_result(
                        "JSONLæ–‡ä»¶æ ¼å¼ä¸åŒ¹é…ï¼šæ–‡ä»¶æ˜¯ä¸ºClaudeæ¨¡åž‹ç”Ÿæˆçš„ï¼ˆåŒ…å«max_tokensï¼‰ï¼Œ"
                        "ä½†æ‚¨é€‰æ‹©äº†Novaæ¨¡åž‹ã€‚è¯·ä½¿ç”¨åŒ¹é…çš„æ¨¡åž‹æˆ–é‡æ–°ç”ŸæˆJSONLæ–‡ä»¶ã€‚"
                    )
                elif not is_nova_model and is_nova_format:
                    logger.warning("âš ï¸ JSONLæ–‡ä»¶ä¸ºNovaæ ¼å¼ï¼Œä½†é€‰æ‹©äº†Claudeæ¨¡åž‹")
                    return self._error_result(
                        "JSONLæ–‡ä»¶æ ¼å¼ä¸åŒ¹é…ï¼šæ–‡ä»¶æ˜¯ä¸ºNovaæ¨¡åž‹ç”Ÿæˆçš„ï¼ˆåŒ…å«inferenceConfigï¼‰ï¼Œ"
                        "ä½†æ‚¨é€‰æ‹©äº†Claudeæ¨¡åž‹ã€‚è¯·ä½¿ç”¨åŒ¹é…çš„æ¨¡åž‹æˆ–é‡æ–°ç”ŸæˆJSONLæ–‡ä»¶ã€‚"
                    )
                
                logger.debug(f"JSONLæ ¼å¼æ£€æŸ¥é€šè¿‡ - Novaæ¨¡åž‹: {is_nova_model}, Novaæ ¼å¼: {is_nova_format}, Claudeæ ¼å¼: {is_claude_format}")
            else:
                # åŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªtxtæ–‡ä»¶
                logger.debug("åŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼šéšæœºé€‰æ‹©txtæ–‡ä»¶")
                files = self.s3_manager.list_files(input_bucket, input_prefix)
                txt_files = [f for f in files if f['file_name'].lower().endswith('.txt')]
                
                if not txt_files:
                    return self._error_result("æœªæ‰¾åˆ°ä»»ä½•.txtæ–‡ä»¶")
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªæ–‡ä»¶
                selected_file = random.choice(txt_files)
                file_info = f"æ–‡ä»¶: {selected_file['file_name']} ({selected_file['size']} bytes)"
                logger.info(f"é€‰ä¸­æ–‡ä»¶: {selected_file['file_name']}")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                content = self.s3_manager.read_file(input_bucket, selected_file['file_path'])
                
                # æ ¹æ®æ¨¡åž‹ç±»åž‹ç»„è£…ä¸åŒæ ¼å¼çš„è¾“å…¥
                if 'nova' in model_id.lower():
                    # Novaæ¨¡åž‹ä½¿ç”¨åŽŸç”ŸAPIæ ¼å¼
                    model_input = {
                        "schemaVersion": "messages-v1",
                        "messages": [{
                            "role": "user",
                            "content": [{"text": f"{prompt}\n\n{content}"}]
                        }],
                        "inferenceConfig": {
                            "maxTokens": 2048,
                            "temperature": 0.1,
                            "topP": 0.9
                        }
                    }
                else:
                    # Claudeæ¨¡åž‹ä½¿ç”¨Messages APIæ ¼å¼
                    model_input = {
                        "anthropic_version": "bedrock-2023-05-31",
                        "max_tokens": 2048,
                        "temperature": 0.1,
                        "messages": [{
                            "role": "user",
                            "content": f"{prompt}\n\n{content}"
                        }]
                    }
            
            # è°ƒç”¨æ¨¡åž‹
            logger.debug("è°ƒç”¨Bedrock Runtimeè¿›è¡ŒæŽ¨ç†...")
            start_time = datetime.now()
            response = self.bedrock_runtime.invoke_model(
                modelId=model_id,
                body=json.dumps(model_input)
            )
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # è§£æžå“åº”ï¼ˆæ ¹æ®æ¨¡åž‹ç±»åž‹ä½¿ç”¨ä¸åŒæ ¼å¼ï¼‰
            response_body = json.loads(response['body'].read())
            
            if 'nova' in model_id.lower():
                # Novaæ¨¡åž‹å“åº”æ ¼å¼
                output_text = response_body['output']['message']['content'][0]['text']
                stop_reason = response_body['output'].get('stopReason', 'unknown')
                input_tokens = response_body.get('usage', {}).get('inputTokens', 0)
                output_tokens = response_body.get('usage', {}).get('outputTokens', 0)
            else:
                # Claudeæ¨¡åž‹å“åº”æ ¼å¼
                output_text = response_body['content'][0]['text']
                stop_reason = response_body.get('stop_reason', 'unknown')
                input_tokens = response_body.get('usage', {}).get('input_tokens', 0)
                output_tokens = response_body.get('usage', {}).get('output_tokens', 0)
            
            logger.info(f"âœ… æŽ¨ç†æˆåŠŸï¼è€—æ—¶: {duration:.2f}ç§’, è¾“å…¥tokens: {input_tokens}, è¾“å‡ºtokens: {output_tokens}")
            
            return self._success_result(
                file_info=file_info,
                prompt=prompt if not use_jsonl else "æ¥è‡ªJSONLæ–‡ä»¶",
                output_text=output_text,
                stop_reason=stop_reason,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                duration=duration,
                model_input=model_input
            )
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {str(e)}", exc_info=True)
            return self._error_result(str(e))
    
    def validate_image_inference(
        self,
        use_jsonl: bool,
        input_bucket: str,
        input_prefix: str,
        jsonl_s3_uri: str,
        system_prompt: str,
        user_prompt: str,
        model_id: str
    ) -> Dict:
        """éªŒè¯å›¾ç‰‡æ‰¹å¤„ç†çš„å•æ¬¡æŽ¨ç†"""
        logger.info("ðŸ§ª å¼€å§‹å›¾ç‰‡æŽ¨ç†éªŒè¯...")
        try:
            if use_jsonl:
                # JSONLæ¨¡å¼ï¼šè¯»å–ç¬¬ä¸€ä¸ªitem
                logger.debug("JSONLæ¨¡å¼ï¼šè¯»å–ç¬¬ä¸€ä¸ªitem")
                model_input, file_info = self._get_first_jsonl_item(jsonl_s3_uri)
                
                # æ£€æŸ¥JSONLæ ¼å¼æ˜¯å¦ä¸Žå½“å‰æ¨¡åž‹åŒ¹é…
                is_nova_model = 'nova' in model_id.lower()
                is_nova_format = 'schemaVersion' in model_input and 'inferenceConfig' in model_input
                is_claude_format = 'anthropic_version' in model_input and 'max_tokens' in model_input
                
                if is_nova_model and is_claude_format:
                    logger.warning("âš ï¸ JSONLæ–‡ä»¶ä¸ºClaudeæ ¼å¼ï¼Œä½†é€‰æ‹©äº†Novaæ¨¡åž‹")
                    return self._error_result(
                        "JSONLæ–‡ä»¶æ ¼å¼ä¸åŒ¹é…ï¼šæ–‡ä»¶æ˜¯ä¸ºClaudeæ¨¡åž‹ç”Ÿæˆçš„ï¼ˆåŒ…å«max_tokensï¼‰ï¼Œ"
                        "ä½†æ‚¨é€‰æ‹©äº†Novaæ¨¡åž‹ã€‚è¯·ä½¿ç”¨åŒ¹é…çš„æ¨¡åž‹æˆ–é‡æ–°ç”ŸæˆJSONLæ–‡ä»¶ã€‚"
                    )
                elif not is_nova_model and is_nova_format:
                    logger.warning("âš ï¸ JSONLæ–‡ä»¶ä¸ºNovaæ ¼å¼ï¼Œä½†é€‰æ‹©äº†Claudeæ¨¡åž‹")
                    return self._error_result(
                        "JSONLæ–‡ä»¶æ ¼å¼ä¸åŒ¹é…ï¼šæ–‡ä»¶æ˜¯ä¸ºNovaæ¨¡åž‹ç”Ÿæˆçš„ï¼ˆåŒ…å«inferenceConfigï¼‰ï¼Œ"
                        "ä½†æ‚¨é€‰æ‹©äº†Claudeæ¨¡åž‹ã€‚è¯·ä½¿ç”¨åŒ¹é…çš„æ¨¡åž‹æˆ–é‡æ–°ç”ŸæˆJSONLæ–‡ä»¶ã€‚"
                    )
                
                logger.debug(f"JSONLæ ¼å¼æ£€æŸ¥é€šè¿‡ - Novaæ¨¡åž‹: {is_nova_model}, Novaæ ¼å¼: {is_nova_format}, Claudeæ ¼å¼: {is_claude_format}")
            else:
                # åŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªå›¾ç‰‡
                files = self.s3_manager.list_files(input_bucket, input_prefix)
                image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']
                image_files = [f for f in files if any(f['file_name'].lower().endswith(ext) for ext in image_extensions)]
                
                if not image_files:
                    return self._error_result("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
                
                selected_file = random.choice(image_files)
                file_info = f"æ–‡ä»¶: {selected_file['file_name']} ({selected_file['size']} bytes)"
                logger.info(f"é€‰ä¸­æ–‡ä»¶: {selected_file['file_name']}")
                
                # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
                image_data = self.s3_manager.read_binary_file(input_bucket, selected_file['file_path'])
                base64_image = base64.b64encode(image_data).decode('utf-8')
                
                # ç¡®å®šå›¾ç‰‡æ ¼å¼
                image_format = selected_file['file_name'].lower().split('.')[-1]
                if image_format == 'jpg':
                    image_format = 'jpeg'
                
                # æ ¹æ®æ¨¡åž‹ç±»åž‹ç»„è£…ä¸åŒæ ¼å¼
                if 'nova' in model_id.lower():
                    # Novaæ¨¡åž‹ä½¿ç”¨åŽŸç”ŸAPIæ ¼å¼
                    content = [
                        {
                            "image": {
                                "format": image_format,
                                "source": {"bytes": base64_image}
                            }
                        }
                    ]
                    if user_prompt:
                        content.append({"text": user_prompt})
                    
                    messages = [{"role": "user", "content": content}]
                    
                    system_list = []
                    if system_prompt:
                        system_list.append({"text": system_prompt})
                    
                    model_input = {
                        "schemaVersion": "messages-v1",
                        "messages": messages,
                        "inferenceConfig": {
                            "maxTokens": 300,
                            "temperature": 0.1,
                            "topP": 0.9
                        }
                    }
                    if system_list:
                        model_input["system"] = system_list
                else:
                    # Claudeæ¨¡åž‹ä½¿ç”¨Messages APIæ ¼å¼
                    content = [{
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": f"image/{image_format}",
                            "data": base64_image
                        }
                    }]
                    
                    if user_prompt:
                        content.append({"type": "text", "text": user_prompt})
                    
                    messages = [{"role": "user", "content": content}]
                    
                    model_input = {
                        "anthropic_version": "bedrock-2023-05-31",
                        "max_tokens": 300,
                        "temperature": 0.1
                    }
                    
                    if system_prompt:
                        model_input["system"] = system_prompt
                    
                    model_input["messages"] = messages
            
            # è°ƒç”¨æ¨¡åž‹
            start_time = datetime.now()
            response = self.bedrock_runtime.invoke_model(
                modelId=model_id,
                body=json.dumps(model_input)
            )
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # è§£æžå“åº”ï¼ˆæ ¹æ®æ¨¡åž‹ç±»åž‹ä½¿ç”¨ä¸åŒæ ¼å¼ï¼‰
            response_body = json.loads(response['body'].read())
            
            if 'nova' in model_id.lower():
                # Novaæ¨¡åž‹å“åº”æ ¼å¼
                output_text = response_body['output']['message']['content'][0]['text']
                stop_reason = response_body['output'].get('stopReason', 'unknown')
                input_tokens = response_body.get('usage', {}).get('inputTokens', 0)
                output_tokens = response_body.get('usage', {}).get('outputTokens', 0)
            else:
                # Claudeæ¨¡åž‹å“åº”æ ¼å¼
                output_text = response_body['content'][0]['text']
                stop_reason = response_body.get('stop_reason', 'unknown')
                input_tokens = response_body.get('usage', {}).get('input_tokens', 0)
                output_tokens = response_body.get('usage', {}).get('output_tokens', 0)
            
            logger.info(f"âœ… æŽ¨ç†æˆåŠŸï¼è€—æ—¶: {duration:.2f}ç§’")
            
            return self._success_result(
                file_info=file_info,
                prompt=f"System: {system_prompt}\nUser: {user_prompt}" if not use_jsonl else "æ¥è‡ªJSONLæ–‡ä»¶",
                output_text=output_text,
                stop_reason=stop_reason,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                duration=duration,
                model_input=model_input
            )
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {str(e)}", exc_info=True)
            return self._error_result(str(e))
    
    def validate_video_inference(
        self,
        use_jsonl: bool,
        input_bucket: str,
        input_prefix: str,
        jsonl_s3_uri: str,
        system_prompt: str,
        user_prompt: str,
        model_id: str
    ) -> Dict:
        """éªŒè¯è§†é¢‘æ‰¹å¤„ç†çš„å•æ¬¡æŽ¨ç†"""
        logger.info("ðŸ§ª å¼€å§‹è§†é¢‘æŽ¨ç†éªŒè¯...")
        try:
            if use_jsonl:
                # JSONLæ¨¡å¼
                model_input, file_info = self._get_first_jsonl_item(jsonl_s3_uri)
            else:
                # åŽŸå§‹æ–‡ä»¶æ¨¡å¼ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘
                files = self.s3_manager.list_files(input_bucket, input_prefix)
                video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv']
                video_files = [f for f in files if any(f['file_name'].lower().endswith(ext) for ext in video_extensions)]
                
                if not video_files:
                    return self._error_result("æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
                
                selected_file = random.choice(video_files)
                file_info = f"æ–‡ä»¶: {selected_file['file_name']} ({selected_file['size']} bytes)"
                logger.info(f"é€‰ä¸­æ–‡ä»¶: {selected_file['file_name']}")
                
                # è¯»å–å¹¶ç¼–ç è§†é¢‘
                video_data = self.s3_manager.read_binary_file(input_bucket, selected_file['file_path'])
                base64_video = base64.b64encode(video_data).decode('utf-8')
                
                # ç¡®å®šè§†é¢‘æ ¼å¼
                video_format = selected_file['file_name'].lower().split('.')[-1]
                
                # ç»„è£…Novaæ ¼å¼
                messages = [{
                    "role": "user",
                    "content": [
                        {
                            "video": {
                                "format": video_format,
                                "source": {"bytes": base64_video}
                            }
                        },
                        {"text": user_prompt}
                    ]
                }]
                
                system_list = []
                if system_prompt:
                    system_list.append({"text": system_prompt})
                else:
                    system_list.append({"text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†æžåŠ©æ‰‹ã€‚"})
                
                model_input = {
                    "schemaVersion": "messages-v1",
                    "messages": messages,
                    "system": system_list,
                    "inferenceConfig": {
                        "maxTokens": 300,
                        "topP": 0.1,
                        "topK": 20,
                        "temperature": 0.3
                    }
                }
            
            # è°ƒç”¨æ¨¡åž‹
            start_time = datetime.now()
            response = self.bedrock_runtime.invoke_model(
                modelId=model_id,
                body=json.dumps(model_input)
            )
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # è§£æžå“åº”ï¼ˆNovaæ ¼å¼ï¼‰
            response_body = json.loads(response['body'].read())
            output_text = response_body['output']['message']['content'][0]['text']
            stop_reason = response_body['output'].get('stopReason', 'unknown')
            input_tokens = response_body.get('usage', {}).get('inputTokens', 0)
            output_tokens = response_body.get('usage', {}).get('outputTokens', 0)
            
            logger.info(f"âœ… æŽ¨ç†æˆåŠŸï¼è€—æ—¶: {duration:.2f}ç§’")
            
            return self._success_result(
                file_info=file_info,
                prompt=f"System: {system_prompt}\nUser: {user_prompt}" if not use_jsonl else "æ¥è‡ªJSONLæ–‡ä»¶",
                output_text=output_text,
                stop_reason=stop_reason,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                duration=duration,
                model_input=model_input
            )
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {str(e)}", exc_info=True)
            return self._error_result(str(e))
    
    def _get_first_jsonl_item(self, jsonl_s3_uri: str) -> Tuple[Dict, str]:
        """
        ä»ŽJSONLæ–‡ä»¶è¯»å–ç¬¬ä¸€ä¸ªitem
        
        Returns:
            (model_input, file_info)
        """
        # è§£æžS3 URI
        s3_path = jsonl_s3_uri.replace('s3://', '')
        parts = s3_path.split('/', 1)
        bucket = parts[0]
        key = parts[1] if len(parts) > 1 else ''
        
        logger.debug(f"è¯»å–JSONLæ–‡ä»¶: s3://{bucket}/{key}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_response = self.s3_manager.s3.get_object(Bucket=bucket, Key=key)
        content = file_response['Body'].read().decode('utf-8')
        
        # èŽ·å–ç¬¬ä¸€è¡Œ
        first_line = content.strip().split('\n')[0]
        item = json.loads(first_line)
        
        # æå–modelInput
        model_input = item.get('modelInput', {})
        record_id = item.get('recordId', 'unknown')
        
        file_info = f"JSONL Record ID: {record_id}"
        logger.debug(f"å·²è¯»å–JSONLç¬¬ä¸€ä¸ªitem: {record_id}")
        
        return model_input, file_info
    
    def _success_result(
        self,
        file_info: str,
        prompt: str,
        output_text: str,
        stop_reason: str,
        input_tokens: int,
        output_tokens: int,
        duration: float,
        model_input: Dict
    ) -> Dict:
        """æž„å»ºæˆåŠŸç»“æžœ"""
        return {
            'success': True,
            'file_info': file_info,
            'prompt': prompt,
            'output_text': output_text,
            'stop_reason': stop_reason,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'duration': duration,
            'model_input_preview': json.dumps(model_input, ensure_ascii=False, indent=2)[:500] + '...'
        }
    
    def _error_result(self, error_message: str) -> Dict:
        """æž„å»ºé”™è¯¯ç»“æžœ"""
        return {
            'success': False,
            'error': error_message
        }
